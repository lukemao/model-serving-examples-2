{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers\n",
    "pip3 install transformers==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "from torch.nn import functional as F\n",
    "import tensorflow as tf\n",
    "import operator\n",
    "import pprint\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('deepset/sentence_bert')\n",
    "model = AutoModel.from_pretrained('deepset/sentence_bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['unhappy', 'happy', \n",
    "           'positive', 'negative', 'neutral']\n",
    "\n",
    "sentence = '''\n",
    "Hi, \n",
    "I had very good experience in using the service.\n",
    "I have recently made use of Virtual Shopping to help me to rearrang home delivery for my order.\n",
    "Because I want to change the delivery date, can you share the instructions.\n",
    "Kindly regards,\n",
    "Lu\n",
    "'''\n",
    "[sentence] + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and tokenize the sentence and labels\n",
    "inputs = tokenizer.batch_encode_plus([sentence] + labels,\n",
    "                                     return_tensors='pt',\n",
    "                                     pad_to_max_length=True)\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = 'Sentence submitted for labelling \\n' + str(sentence)+'\\n'\n",
    "\n",
    "output = model(input_ids, attention_mask=attention_mask)[0]\n",
    "sentence_emb = output[:1].mean(dim=1)\n",
    "label_emb = output[1:].mean(dim=1)\n",
    "\n",
    "print(output.shape)\n",
    "print(sentence_emb.shape)\n",
    "print(label_emb.shape)\n",
    "    \n",
    "similarities = F.cosine_similarity(sentence_emb, label_emb)\n",
    "closest = similarities.argsort(descending=True)\n",
    "\n",
    "result = dict(zip(labels, similarities.tolist()))\n",
    "sorted_d = sorted(result.items(), key=operator.itemgetter(1), reverse=True)\n",
    "pprint.pprint(sorted_d)\n",
    "\n",
    "\n",
    "print('Assigned Labels')\n",
    "for ind in closest:\n",
    "    response += f'label: {labels[ind]}    \\t similarity: {round(similarities[ind].item(), 2)} \\n'\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similarities.tolist())\n",
    "print(closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MODEL_DIR = \"/Users/napt/Workspace/gft/model-serving-examples/aiplatform/model_files/model.pt\"\n",
    "torch.save(model, LOCAL_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh model_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls model_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/Users/napt/Workspace/gft/model-serving-examples/aiplatform/model_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(model_dir, 'model.pt')\n",
    "print(model_file)\n",
    "model = torch.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids, attention_mask=attention_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "\n",
    "\n",
    "class EmailClassifier(object):\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "        self.class_lables = ['unhappy', 'happy', 'positive', 'negative', 'neutral']\n",
    "\n",
    "    @classmethod\n",
    "    def from_path(cls, model_dir):\n",
    "        model_file = os.path.join(model_dir, 'model.pt')\n",
    "        model = torch.load(model_file)\n",
    "        return cls(model)\n",
    "\n",
    "    def predict(self, sentence, **kwargs):\n",
    "        inputs = tokenizer.batch_encode_plus([sentence] + self.class_lables,\n",
    "                                             return_tensors='pt',\n",
    "                                             pad_to_max_length=True)\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        output = self._model(input_ids, attention_mask=attention_mask)[0]\n",
    "        sentence_emb = output[:1].mean(dim=1)\n",
    "        label_emb = output[1:].mean(dim=1)\n",
    "\n",
    "        similarities = F.cosine_similarity(sentence_emb, label_emb)\n",
    "\n",
    "        result = dict(zip(self.class_lables, similarities.tolist()))\n",
    "        predicted = sorted(result.items(), key=operator.itemgetter(1),\n",
    "                           reverse=True)\n",
    "\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmailClassifier.from_path(model_dir)\n",
    "eclass = EmailClassifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclass.model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(model_dir, 'model.pt')\n",
    "model = torch.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.batch_encode_plus([sentence] + labels,\n",
    "                                             return_tensors='pt',\n",
    "                                             pad_to_max_length=True)\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "output = model(input_ids, attention_mask=attention_mask)[0]\n",
    "sentence_emb = output[:1].mean(dim=1)\n",
    "label_emb = output[1:].mean(dim=1)\n",
    "\n",
    "similarities = F.cosine_similarity(sentence_emb, label_emb)\n",
    "\n",
    "result = dict(zip(labels, similarities.tolist()))\n",
    "predicted = sorted(result.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
